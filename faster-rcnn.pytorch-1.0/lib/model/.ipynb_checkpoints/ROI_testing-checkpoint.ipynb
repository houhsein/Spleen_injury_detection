{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "import os.path as osp\n",
    "import sys\n",
    "#sys.path.append(osp.abspath(osp.join(__file__, '../../')))\n",
    "from roi_align import RoIAlign, RoIAlign3D # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1)\n",
      "(20, 4)\n",
      "(20, 5)\n",
      "torch.Size([2, 16, 15, 15])\n",
      "Gradcheck for roi align...\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "feat_size = 15\n",
    "spatial_scale = 1.0 / 8\n",
    "img_size = feat_size / spatial_scale\n",
    "num_imgs = 2\n",
    "num_rois = 20\n",
    "\n",
    "batch_ind = np.random.randint(num_imgs, size=(num_rois, 1))\n",
    "print(batch_ind.shape)\n",
    "rois = np.random.rand(num_rois, 4) * img_size * 0.5\n",
    "print(rois.shape)\n",
    "rois[:, 2:] += img_size * 0.5\n",
    "rois = np.hstack((batch_ind, rois))\n",
    "print(rois.shape)\n",
    "\n",
    "feat = torch.randn(\n",
    "    num_imgs, 16, feat_size, feat_size, requires_grad=True, device='cuda:0')\n",
    "print(feat.shape)\n",
    "rois = torch.from_numpy(rois).float().cuda()\n",
    "inputs = (feat, rois)\n",
    "print('Gradcheck for roi align...')\n",
    "# RoIAlign(out_size, spatial_scale, sample_num=0)\n",
    "test = gradcheck(RoIAlign(3, spatial_scale), inputs, atol=1e-3, eps=1e-3)\n",
    "print(test)\n",
    "test = gradcheck(RoIAlign(3, spatial_scale, 2), inputs, atol=1e-3, eps=1e-3)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-0a200f2e2b33>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-0a200f2e2b33>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    test = gradcheck(RoIAlign3D(3, spatial_scale, spatial_scale_depth 2), inputs, atol=1e-3, eps=1e-3)\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "feat_size = 15\n",
    "spatial_scale = 1.0 / 8\n",
    "spatial_scale_depth = spatial_scale\n",
    "img_size = feat_size / spatial_scale\n",
    "num_imgs = 2\n",
    "num_rois = 20\n",
    "\n",
    "batch_ind = np.random.randint(num_imgs, size=(num_rois, 1))\n",
    "print(batch_ind.shape)\n",
    "rois = np.random.rand(num_rois, 6) * img_size * 0.5\n",
    "print(rois.shape)\n",
    "rois[:, 2:4] += img_size * 0.5\n",
    "rois[:, 5] += img_size * 0.5\n",
    "rois = np.hstack((batch_ind, rois))\n",
    "print(rois.shape)\n",
    "\n",
    "\n",
    "feat = torch.randn(\n",
    "    num_imgs, 16, feat_size, feat_size, feat_size, requires_grad=True, device='cuda:0')\n",
    "print(feat.shape)\n",
    "rois = torch.from_numpy(rois).float().cuda()\n",
    "inputs = (feat, rois)\n",
    "print('Gradcheck for roi align...')\n",
    "# RoIAlign3D(out_size, out_size_depth, spatial_scale, spatial_scale_depth, sample_num=0)\n",
    "test = gradcheck(RoIAlign3D(3, spatial_scale, spatial_scale_depth), inputs, atol=1e-3, eps=1e-3)\n",
    "print(test)\n",
    "test = gradcheck(RoIAlign3D(3, spatial_scale, spatial_scale_depth 2), inputs, atol=1e-3, eps=1e-3)\n",
    "print(test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
